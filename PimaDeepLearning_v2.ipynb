{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Read Data\n",
    "data = pd.read_csv(\"data.csv\", header = None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "np.random.seed(7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6</td>\n",
       "      <td>148</td>\n",
       "      <td>72</td>\n",
       "      <td>35</td>\n",
       "      <td>0</td>\n",
       "      <td>33.6</td>\n",
       "      <td>0.627</td>\n",
       "      <td>50</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>85</td>\n",
       "      <td>66</td>\n",
       "      <td>29</td>\n",
       "      <td>0</td>\n",
       "      <td>26.6</td>\n",
       "      <td>0.351</td>\n",
       "      <td>31</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8</td>\n",
       "      <td>183</td>\n",
       "      <td>64</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>23.3</td>\n",
       "      <td>0.672</td>\n",
       "      <td>32</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>89</td>\n",
       "      <td>66</td>\n",
       "      <td>23</td>\n",
       "      <td>94</td>\n",
       "      <td>28.1</td>\n",
       "      <td>0.167</td>\n",
       "      <td>21</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>137</td>\n",
       "      <td>40</td>\n",
       "      <td>35</td>\n",
       "      <td>168</td>\n",
       "      <td>43.1</td>\n",
       "      <td>2.288</td>\n",
       "      <td>33</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   0    1   2   3    4     5      6   7  8\n",
       "0  6  148  72  35    0  33.6  0.627  50  1\n",
       "1  1   85  66  29    0  26.6  0.351  31  0\n",
       "2  8  183  64   0    0  23.3  0.672  32  1\n",
       "3  1   89  66  23   94  28.1  0.167  21  0\n",
       "4  0  137  40  35  168  43.1  2.288  33  1"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X=data.values[:,0:8]\n",
    "Y=data.values[:,8]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(12, input_dim=8, activation='relu'))\n",
    "model.add(Dense(8, activation='relu'))\n",
    "model.add(Dense(1,activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.compile(loss='binary_crossentropy', optimizer='adam',metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150\n",
      "768/768 [==============================] - 2s - loss: 3.7276 - acc: 0.5990     \n",
      "Epoch 2/150\n",
      "768/768 [==============================] - 0s - loss: 0.9376 - acc: 0.5964     \n",
      "Epoch 3/150\n",
      "768/768 [==============================] - 0s - loss: 0.7488 - acc: 0.6484     \n",
      "Epoch 4/150\n",
      "768/768 [==============================] - 0s - loss: 0.7129 - acc: 0.6523     \n",
      "Epoch 5/150\n",
      "768/768 [==============================] - 0s - loss: 0.6850 - acc: 0.6667     \n",
      "Epoch 6/150\n",
      "768/768 [==============================] - 0s - loss: 0.6538 - acc: 0.6784     \n",
      "Epoch 7/150\n",
      "768/768 [==============================] - 0s - loss: 0.6538 - acc: 0.6784     \n",
      "Epoch 8/150\n",
      "768/768 [==============================] - 0s - loss: 0.6427 - acc: 0.6849     \n",
      "Epoch 9/150\n",
      "768/768 [==============================] - 0s - loss: 0.6291 - acc: 0.6927     \n",
      "Epoch 10/150\n",
      "768/768 [==============================] - 0s - loss: 0.6358 - acc: 0.6706     \n",
      "Epoch 11/150\n",
      "768/768 [==============================] - 0s - loss: 0.6537 - acc: 0.6693     \n",
      "Epoch 12/150\n",
      "768/768 [==============================] - 0s - loss: 0.6419 - acc: 0.6680     \n",
      "Epoch 13/150\n",
      "768/768 [==============================] - 0s - loss: 0.6283 - acc: 0.6771     \n",
      "Epoch 14/150\n",
      "768/768 [==============================] - 0s - loss: 0.6203 - acc: 0.6979     \n",
      "Epoch 15/150\n",
      "768/768 [==============================] - 0s - loss: 0.6025 - acc: 0.6979     \n",
      "Epoch 16/150\n",
      "768/768 [==============================] - 0s - loss: 0.5880 - acc: 0.7018     \n",
      "Epoch 17/150\n",
      "768/768 [==============================] - 0s - loss: 0.5840 - acc: 0.7031     \n",
      "Epoch 18/150\n",
      "768/768 [==============================] - 0s - loss: 0.6007 - acc: 0.6914     \n",
      "Epoch 19/150\n",
      "768/768 [==============================] - 0s - loss: 0.5797 - acc: 0.7148     \n",
      "Epoch 20/150\n",
      "768/768 [==============================] - 0s - loss: 0.5784 - acc: 0.7214     \n",
      "Epoch 21/150\n",
      "768/768 [==============================] - 0s - loss: 0.5681 - acc: 0.7122     \n",
      "Epoch 22/150\n",
      "768/768 [==============================] - 0s - loss: 0.5817 - acc: 0.7005     \n",
      "Epoch 23/150\n",
      "768/768 [==============================] - 0s - loss: 0.5738 - acc: 0.7109     \n",
      "Epoch 24/150\n",
      "768/768 [==============================] - 0s - loss: 0.5697 - acc: 0.7305     \n",
      "Epoch 25/150\n",
      "768/768 [==============================] - 0s - loss: 0.5572 - acc: 0.7383     \n",
      "Epoch 26/150\n",
      "768/768 [==============================] - 0s - loss: 0.5701 - acc: 0.7070     \n",
      "Epoch 27/150\n",
      "768/768 [==============================] - 0s - loss: 0.5556 - acc: 0.7266     \n",
      "Epoch 28/150\n",
      "768/768 [==============================] - 0s - loss: 0.5550 - acc: 0.7344     \n",
      "Epoch 29/150\n",
      "768/768 [==============================] - 0s - loss: 0.5738 - acc: 0.7174     \n",
      "Epoch 30/150\n",
      "768/768 [==============================] - 0s - loss: 0.5609 - acc: 0.7214     \n",
      "Epoch 31/150\n",
      "768/768 [==============================] - 0s - loss: 0.5688 - acc: 0.7214     \n",
      "Epoch 32/150\n",
      "768/768 [==============================] - 0s - loss: 0.5637 - acc: 0.7188     \n",
      "Epoch 33/150\n",
      "768/768 [==============================] - 0s - loss: 0.5513 - acc: 0.7253     \n",
      "Epoch 34/150\n",
      "768/768 [==============================] - 0s - loss: 0.5480 - acc: 0.7318     \n",
      "Epoch 35/150\n",
      "768/768 [==============================] - 0s - loss: 0.5506 - acc: 0.7214     \n",
      "Epoch 36/150\n",
      "768/768 [==============================] - 0s - loss: 0.5610 - acc: 0.7083     \n",
      "Epoch 37/150\n",
      "768/768 [==============================] - 0s - loss: 0.5352 - acc: 0.7396     \n",
      "Epoch 38/150\n",
      "768/768 [==============================] - 0s - loss: 0.5410 - acc: 0.7240     \n",
      "Epoch 39/150\n",
      "768/768 [==============================] - 0s - loss: 0.5462 - acc: 0.7240     \n",
      "Epoch 40/150\n",
      "768/768 [==============================] - 0s - loss: 0.5448 - acc: 0.7292     \n",
      "Epoch 41/150\n",
      "768/768 [==============================] - 0s - loss: 0.5433 - acc: 0.7318     \n",
      "Epoch 42/150\n",
      "768/768 [==============================] - 0s - loss: 0.5379 - acc: 0.7448     \n",
      "Epoch 43/150\n",
      "768/768 [==============================] - 0s - loss: 0.5310 - acc: 0.7526     \n",
      "Epoch 44/150\n",
      "768/768 [==============================] - 0s - loss: 0.5329 - acc: 0.7422     \n",
      "Epoch 45/150\n",
      "768/768 [==============================] - 0s - loss: 0.5332 - acc: 0.7578     \n",
      "Epoch 46/150\n",
      "768/768 [==============================] - 0s - loss: 0.5281 - acc: 0.7474     \n",
      "Epoch 47/150\n",
      "768/768 [==============================] - 0s - loss: 0.5307 - acc: 0.7383     \n",
      "Epoch 48/150\n",
      "768/768 [==============================] - 0s - loss: 0.5322 - acc: 0.7383     \n",
      "Epoch 49/150\n",
      "768/768 [==============================] - 0s - loss: 0.5329 - acc: 0.7474     \n",
      "Epoch 50/150\n",
      "768/768 [==============================] - 0s - loss: 0.5269 - acc: 0.7331     \n",
      "Epoch 51/150\n",
      "768/768 [==============================] - 0s - loss: 0.5287 - acc: 0.7487     \n",
      "Epoch 52/150\n",
      "768/768 [==============================] - 0s - loss: 0.5307 - acc: 0.7461     \n",
      "Epoch 53/150\n",
      "768/768 [==============================] - 0s - loss: 0.5378 - acc: 0.7474     \n",
      "Epoch 54/150\n",
      "768/768 [==============================] - 0s - loss: 0.5380 - acc: 0.7253     \n",
      "Epoch 55/150\n",
      "768/768 [==============================] - 0s - loss: 0.5227 - acc: 0.7526     \n",
      "Epoch 56/150\n",
      "768/768 [==============================] - 0s - loss: 0.5290 - acc: 0.7474     \n",
      "Epoch 57/150\n",
      "768/768 [==============================] - 0s - loss: 0.5294 - acc: 0.7435     \n",
      "Epoch 58/150\n",
      "768/768 [==============================] - 0s - loss: 0.5218 - acc: 0.7552     \n",
      "Epoch 59/150\n",
      "768/768 [==============================] - 0s - loss: 0.5116 - acc: 0.7695     \n",
      "Epoch 60/150\n",
      "768/768 [==============================] - 0s - loss: 0.5322 - acc: 0.7474     \n",
      "Epoch 61/150\n",
      "768/768 [==============================] - 0s - loss: 0.5240 - acc: 0.7461     \n",
      "Epoch 62/150\n",
      "768/768 [==============================] - 0s - loss: 0.5156 - acc: 0.7552     \n",
      "Epoch 63/150\n",
      "768/768 [==============================] - 0s - loss: 0.5427 - acc: 0.7344     \n",
      "Epoch 64/150\n",
      "768/768 [==============================] - 0s - loss: 0.5299 - acc: 0.7422     \n",
      "Epoch 65/150\n",
      "768/768 [==============================] - 0s - loss: 0.5194 - acc: 0.7552     \n",
      "Epoch 66/150\n",
      "768/768 [==============================] - 0s - loss: 0.5057 - acc: 0.7526     \n",
      "Epoch 67/150\n",
      "768/768 [==============================] - 0s - loss: 0.5162 - acc: 0.7422     \n",
      "Epoch 68/150\n",
      "768/768 [==============================] - 0s - loss: 0.5138 - acc: 0.7578     \n",
      "Epoch 69/150\n",
      "768/768 [==============================] - 0s - loss: 0.5136 - acc: 0.7578     \n",
      "Epoch 70/150\n",
      "768/768 [==============================] - 0s - loss: 0.5335 - acc: 0.7279     \n",
      "Epoch 71/150\n",
      "768/768 [==============================] - 0s - loss: 0.5152 - acc: 0.7526     \n",
      "Epoch 72/150\n",
      "768/768 [==============================] - 0s - loss: 0.5156 - acc: 0.7578     \n",
      "Epoch 73/150\n",
      "768/768 [==============================] - 0s - loss: 0.5146 - acc: 0.7552     \n",
      "Epoch 74/150\n",
      "768/768 [==============================] - 0s - loss: 0.5093 - acc: 0.7669     \n",
      "Epoch 75/150\n",
      "768/768 [==============================] - 0s - loss: 0.5086 - acc: 0.7604     \n",
      "Epoch 76/150\n",
      "768/768 [==============================] - 0s - loss: 0.5096 - acc: 0.7617     \n",
      "Epoch 77/150\n",
      "768/768 [==============================] - 0s - loss: 0.5136 - acc: 0.7682     \n",
      "Epoch 78/150\n",
      "768/768 [==============================] - 0s - loss: 0.5086 - acc: 0.7500     \n",
      "Epoch 79/150\n",
      "768/768 [==============================] - 0s - loss: 0.5100 - acc: 0.7513     \n",
      "Epoch 80/150\n",
      "768/768 [==============================] - 0s - loss: 0.5070 - acc: 0.7617     \n",
      "Epoch 81/150\n",
      "768/768 [==============================] - 0s - loss: 0.5032 - acc: 0.7721     \n",
      "Epoch 82/150\n",
      "768/768 [==============================] - 0s - loss: 0.5025 - acc: 0.7643     \n",
      "Epoch 83/150\n",
      "768/768 [==============================] - 0s - loss: 0.5005 - acc: 0.7669     \n",
      "Epoch 84/150\n",
      "768/768 [==============================] - 0s - loss: 0.4958 - acc: 0.7630     \n",
      "Epoch 85/150\n",
      "768/768 [==============================] - 0s - loss: 0.5034 - acc: 0.7578     \n",
      "Epoch 86/150\n",
      "768/768 [==============================] - 0s - loss: 0.5048 - acc: 0.7630     \n",
      "Epoch 87/150\n",
      "768/768 [==============================] - 0s - loss: 0.4969 - acc: 0.7604     \n",
      "Epoch 88/150\n",
      "768/768 [==============================] - 0s - loss: 0.4978 - acc: 0.7643     \n",
      "Epoch 89/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "768/768 [==============================] - 0s - loss: 0.5010 - acc: 0.7773     \n",
      "Epoch 90/150\n",
      "768/768 [==============================] - 0s - loss: 0.5092 - acc: 0.7565     \n",
      "Epoch 91/150\n",
      "768/768 [==============================] - 0s - loss: 0.4980 - acc: 0.7565     \n",
      "Epoch 92/150\n",
      "768/768 [==============================] - 0s - loss: 0.5113 - acc: 0.7487     \n",
      "Epoch 93/150\n",
      "768/768 [==============================] - 0s - loss: 0.4987 - acc: 0.7682     \n",
      "Epoch 94/150\n",
      "768/768 [==============================] - 0s - loss: 0.4962 - acc: 0.7656     \n",
      "Epoch 95/150\n",
      "768/768 [==============================] - 0s - loss: 0.5029 - acc: 0.7513     \n",
      "Epoch 96/150\n",
      "768/768 [==============================] - 0s - loss: 0.4905 - acc: 0.7669     \n",
      "Epoch 97/150\n",
      "768/768 [==============================] - 0s - loss: 0.4992 - acc: 0.7721     \n",
      "Epoch 98/150\n",
      "768/768 [==============================] - 0s - loss: 0.4888 - acc: 0.7682     \n",
      "Epoch 99/150\n",
      "768/768 [==============================] - 0s - loss: 0.4893 - acc: 0.7669     \n",
      "Epoch 100/150\n",
      "768/768 [==============================] - 0s - loss: 0.4842 - acc: 0.7799     \n",
      "Epoch 101/150\n",
      "768/768 [==============================] - 0s - loss: 0.4896 - acc: 0.7721     \n",
      "Epoch 102/150\n",
      "768/768 [==============================] - 0s - loss: 0.4965 - acc: 0.7630     \n",
      "Epoch 103/150\n",
      "768/768 [==============================] - 0s - loss: 0.4987 - acc: 0.7591     \n",
      "Epoch 104/150\n",
      "768/768 [==============================] - 0s - loss: 0.4922 - acc: 0.7943     \n",
      "Epoch 105/150\n",
      "768/768 [==============================] - 0s - loss: 0.5301 - acc: 0.7461     \n",
      "Epoch 106/150\n",
      "768/768 [==============================] - 0s - loss: 0.4896 - acc: 0.7773     \n",
      "Epoch 107/150\n",
      "768/768 [==============================] - 0s - loss: 0.4894 - acc: 0.7799     \n",
      "Epoch 108/150\n",
      "768/768 [==============================] - 0s - loss: 0.4950 - acc: 0.7786     \n",
      "Epoch 109/150\n",
      "768/768 [==============================] - 0s - loss: 0.4866 - acc: 0.7643     \n",
      "Epoch 110/150\n",
      "768/768 [==============================] - 0s - loss: 0.4882 - acc: 0.7773     \n",
      "Epoch 111/150\n",
      "768/768 [==============================] - 0s - loss: 0.4838 - acc: 0.7852     \n",
      "Epoch 112/150\n",
      "768/768 [==============================] - 0s - loss: 0.4874 - acc: 0.7760     \n",
      "Epoch 113/150\n",
      "768/768 [==============================] - 0s - loss: 0.4977 - acc: 0.7604     \n",
      "Epoch 114/150\n",
      "768/768 [==============================] - 0s - loss: 0.4908 - acc: 0.7643     \n",
      "Epoch 115/150\n",
      "768/768 [==============================] - 0s - loss: 0.4895 - acc: 0.7747     \n",
      "Epoch 116/150\n",
      "768/768 [==============================] - 0s - loss: 0.4911 - acc: 0.7708     \n",
      "Epoch 117/150\n",
      "768/768 [==============================] - 0s - loss: 0.4885 - acc: 0.7669     \n",
      "Epoch 118/150\n",
      "768/768 [==============================] - 0s - loss: 0.4861 - acc: 0.7813     \n",
      "Epoch 119/150\n",
      "768/768 [==============================] - 0s - loss: 0.4811 - acc: 0.7773     \n",
      "Epoch 120/150\n",
      "768/768 [==============================] - 0s - loss: 0.4917 - acc: 0.7813     \n",
      "Epoch 121/150\n",
      "768/768 [==============================] - 0s - loss: 0.4903 - acc: 0.7760     \n",
      "Epoch 122/150\n",
      "768/768 [==============================] - 0s - loss: 0.4844 - acc: 0.7786     \n",
      "Epoch 123/150\n",
      "768/768 [==============================] - 0s - loss: 0.4831 - acc: 0.7734     \n",
      "Epoch 124/150\n",
      "768/768 [==============================] - 0s - loss: 0.4825 - acc: 0.7813     \n",
      "Epoch 125/150\n",
      "768/768 [==============================] - 0s - loss: 0.4847 - acc: 0.7786     \n",
      "Epoch 126/150\n",
      "768/768 [==============================] - 0s - loss: 0.4788 - acc: 0.7721     \n",
      "Epoch 127/150\n",
      "768/768 [==============================] - 0s - loss: 0.4866 - acc: 0.7695     \n",
      "Epoch 128/150\n",
      "768/768 [==============================] - 0s - loss: 0.4703 - acc: 0.7813     \n",
      "Epoch 129/150\n",
      "768/768 [==============================] - 0s - loss: 0.4778 - acc: 0.7813     \n",
      "Epoch 130/150\n",
      "768/768 [==============================] - 0s - loss: 0.4707 - acc: 0.7917     \n",
      "Epoch 131/150\n",
      "768/768 [==============================] - 0s - loss: 0.4816 - acc: 0.7708     \n",
      "Epoch 132/150\n",
      "768/768 [==============================] - 0s - loss: 0.4802 - acc: 0.7852     \n",
      "Epoch 133/150\n",
      "768/768 [==============================] - 0s - loss: 0.4811 - acc: 0.7786     \n",
      "Epoch 134/150\n",
      "768/768 [==============================] - 0s - loss: 0.4840 - acc: 0.7786     \n",
      "Epoch 135/150\n",
      "768/768 [==============================] - 0s - loss: 0.4751 - acc: 0.7773     \n",
      "Epoch 136/150\n",
      "768/768 [==============================] - 0s - loss: 0.4726 - acc: 0.7826     \n",
      "Epoch 137/150\n",
      "768/768 [==============================] - 0s - loss: 0.4654 - acc: 0.7826     \n",
      "Epoch 138/150\n",
      "768/768 [==============================] - 0s - loss: 0.4781 - acc: 0.7904     \n",
      "Epoch 139/150\n",
      "768/768 [==============================] - 0s - loss: 0.4630 - acc: 0.7878     \n",
      "Epoch 140/150\n",
      "768/768 [==============================] - 0s - loss: 0.4789 - acc: 0.7839     \n",
      "Epoch 141/150\n",
      "768/768 [==============================] - 0s - loss: 0.4720 - acc: 0.7826     \n",
      "Epoch 142/150\n",
      "768/768 [==============================] - 0s - loss: 0.4826 - acc: 0.7721     \n",
      "Epoch 143/150\n",
      "768/768 [==============================] - 0s - loss: 0.4744 - acc: 0.7786     \n",
      "Epoch 144/150\n",
      "768/768 [==============================] - 0s - loss: 0.4737 - acc: 0.7734     \n",
      "Epoch 145/150\n",
      "768/768 [==============================] - 0s - loss: 0.4864 - acc: 0.7669     \n",
      "Epoch 146/150\n",
      "768/768 [==============================] - 0s - loss: 0.4919 - acc: 0.7721     \n",
      "Epoch 147/150\n",
      "768/768 [==============================] - 0s - loss: 0.4794 - acc: 0.7813     \n",
      "Epoch 148/150\n",
      "768/768 [==============================] - 0s - loss: 0.4696 - acc: 0.7786     \n",
      "Epoch 149/150\n",
      "768/768 [==============================] - 0s - loss: 0.4734 - acc: 0.7643     \n",
      "Epoch 150/150\n",
      "768/768 [==============================] - 0s - loss: 0.4751 - acc: 0.7813     \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x182d25074e0>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X,Y,epochs=150, batch_size=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      " 32/768 [>.............................] - ETA: 0s"
     ]
    }
   ],
   "source": [
    "scores = model.evaluate(X,Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acc 0.794270833333\n"
     ]
    }
   ],
   "source": [
    "print(model.metrics_names[1], scores[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### K-fold Cross Verification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import StratifiedKFold\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acc: 71.43%\n",
      "acc: 70.13%\n",
      "acc: 76.62%\n",
      "acc: 71.43%\n",
      "acc: 79.22%\n",
      "acc: 71.43%\n",
      "acc: 72.73%\n",
      "acc: 63.64%\n",
      "acc: 69.74%\n",
      "acc: 65.79%\n",
      "71.2149700003\n"
     ]
    }
   ],
   "source": [
    "kfold = StratifiedKFold(n_splits=10, shuffle = True, random_state = 7)\n",
    "cvscores=[]\n",
    "for train,test in kfold.split(X,Y):\n",
    "    model = Sequential()\n",
    "    model.add(Dense(12, input_dim=8, activation='relu'))\n",
    "    model.add(Dense(8, activation='relu'))\n",
    "    model.add(Dense(1,activation='sigmoid'))\n",
    "    model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    model.fit(X[train], Y[train], epochs=80, batch_size=10, verbose=0)\n",
    "    #evaluate the model\n",
    "    scores = model.evaluate(X[test],Y[test], verbose=0)\n",
    "    print(\"%s: %.2f%%\" %(model.metrics_names[1], scores[1]*100))\n",
    "    cvscores.append(scores[1]*100)\n",
    "\n",
    "print(np.mean(cvscores))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using Keras with Scikit-Learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Using Built in Function build_fn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from sklearn.model_selection import cross_val_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Function to create model, required for Keras Classifier\n",
    "def create_model():\n",
    "    model = Sequential()\n",
    "    model.add(Dense(10, input_dim=8, activation='relu'))\n",
    "    model.add(Dense(8, activation='relu'))\n",
    "    model.add(Dense(1,activation='sigmoid'))\n",
    "    model.compile(loss='binary_crossentropy', optimizer='adam', metrics = ['accuracy'])\n",
    "    return model\n",
    "\n",
    "np.random.seed(7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = KerasClassifier(build_fn=create_model, epochs=150, batch_size=10, verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Evaluate using KFold CV\n",
    "kfold=StratifiedKFold(n_splits=10, shuffle=True, random_state=7)\n",
    "results=cross_val_score(model, X,Y, cv=kfold)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Grid Search Deep Learning Model Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model(optimizer='rmsprop', init='glorot_uniform'):\n",
    "    model = Sequential()\n",
    "    model.add(Dense(12, input_dim=8, kernel_initializer=init, activation='relu'))\n",
    "    model.add(Dense(8, kernel_initializer=init, activation = 'relu'))\n",
    "    model.add(Dense(1,activation ='sigmoid', kernel_initializer=init))\n",
    "    model.compile(loss='binary_crossentropy', optimizer=optimizer, metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "np.random.seed(7)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = KerasClassifier(build_fn = create_model, verbose=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Grid Search Epochs, batch size and optimizer\n",
    "optimizers=['rmsprop','adam']\n",
    "inits = ['glorot_uniform', 'normal','uniform']\n",
    "epochs=[50,100,150]\n",
    "batches=[5,10,20]\n",
    "param_grid = dict(optimizer = optimizers, epochs=epochs, init=inits)\n",
    "grid = GridSearchCV(estimator=model, param_grid = param_grid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_result = grid.fit(X,Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best: 0.734375 using {'epochs': 150, 'optimizer': 'adam', 'init': 'uniform'}\n",
      "0.662760 (0.033197) with {'epochs': 50, 'optimizer': 'rmsprop', 'init': 'glorot_uniform'}\n",
      "0.653646 (0.027498) with {'epochs': 50, 'optimizer': 'adam', 'init': 'glorot_uniform'}\n",
      "0.695312 (0.005524) with {'epochs': 50, 'optimizer': 'rmsprop', 'init': 'normal'}\n",
      "0.691406 (0.014616) with {'epochs': 50, 'optimizer': 'adam', 'init': 'normal'}\n",
      "0.675781 (0.016877) with {'epochs': 50, 'optimizer': 'rmsprop', 'init': 'uniform'}\n",
      "0.670573 (0.023939) with {'epochs': 50, 'optimizer': 'adam', 'init': 'uniform'}\n",
      "0.670573 (0.016367) with {'epochs': 100, 'optimizer': 'rmsprop', 'init': 'glorot_uniform'}\n",
      "0.661458 (0.035849) with {'epochs': 100, 'optimizer': 'adam', 'init': 'glorot_uniform'}\n",
      "0.710938 (0.019137) with {'epochs': 100, 'optimizer': 'rmsprop', 'init': 'normal'}\n",
      "0.710938 (0.013902) with {'epochs': 100, 'optimizer': 'adam', 'init': 'normal'}\n",
      "0.688802 (0.016367) with {'epochs': 100, 'optimizer': 'rmsprop', 'init': 'uniform'}\n",
      "0.713542 (0.008027) with {'epochs': 100, 'optimizer': 'adam', 'init': 'uniform'}\n",
      "0.641927 (0.043537) with {'epochs': 150, 'optimizer': 'rmsprop', 'init': 'glorot_uniform'}\n",
      "0.683594 (0.019137) with {'epochs': 150, 'optimizer': 'adam', 'init': 'glorot_uniform'}\n",
      "0.714844 (0.008438) with {'epochs': 150, 'optimizer': 'rmsprop', 'init': 'normal'}\n",
      "0.710938 (0.011049) with {'epochs': 150, 'optimizer': 'adam', 'init': 'normal'}\n",
      "0.730469 (0.022097) with {'epochs': 150, 'optimizer': 'rmsprop', 'init': 'uniform'}\n",
      "0.734375 (0.024080) with {'epochs': 150, 'optimizer': 'adam', 'init': 'uniform'}\n"
     ]
    }
   ],
   "source": [
    "#Summarize Results:\n",
    "print(\"Best: %f using %s\" %(grid_result.best_score_, grid_result.best_params_))\n",
    "means = grid_result.cv_results_['mean_test_score']\n",
    "stds = grid_result.cv_results_['std_test_score']\n",
    "params = grid_result.cv_results_['params']\n",
    "\n",
    "for mean, stds, params in zip(means, stds, params):\n",
    "    print (\"%f (%f) with %r\" %(mean, stds,params))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:tensorflow]",
   "language": "python",
   "name": "conda-env-tensorflow-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
